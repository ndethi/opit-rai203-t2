---
title: "Optimizing AI Workloads for an Automotive Manufacturer"
subtitle: "Computing Architectures for AI"
author: "Bogdan Bancescu, Tim Nicholas Döring, Charles Watson Ndethi Kibaki"
date: "April 10, 2025"
format: 
  pptx:
    reference-doc: opit-template.pptx  # Optional: Use your branded template
    slide-number: true
    footer: "OPIT RAI-8003 Assessment Group 5"
---

```{r setup, include=FALSE}
# Load all required libraries
library(ggplot2)    # Essential - used in multiple plots
library(dplyr)      # Essential - used for data manipulation
library(tidyr)      # Essential - used for pivot_longer
#library(ggtext)    # Already commented out
#library(gridExtra) # Not clearly used, comment out
#library(igraph)    # Used in the AI applications slide - replaced
#library(ggraph)    # Used with igraph - replaced
#library(DiagrammeR) # Used for the PoC diagram - replaced
#library(ggwordcloud) # Replace with basic ggplot visualization

# Set default knitr options
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 5.5,
  dpi = 300
)
```

## Introduction & Agenda

**Project Scope**: Optimize AI infrastructure for GlobalDrive Automotive

**Presentation Outline**:

1. Current AI Infrastructure & Challenges
2. Specialized Computing Architectures
3. AI Applications in Automotive Manufacturing
4. Proposed Hybrid Cloud-Edge Strategy
5. Proof of Concept Implementation
6. Performance Improvements & ROI
7. Implementation Roadmap
8. Recommendations

::: {.notes}
- Welcome everyone to our presentation on optimizing AI workloads for GlobalDrive Automotive
- Our team has developed a comprehensive strategy to enhance AI computing architecture
- We'll cover the entire journey from current challenges through implementation
- Our focus is on practical, business-value driven solutions
:::

```{r agenda-diagram}
# Create a simple project diagram
nodes <- data.frame(
  id = 1:4,
  x = c(1, 2, 3, 2),
  y = c(2, 1, 3, 2),
  label = c("Current\nState", "Analysis", "Proposed\nArchitecture", "Implementation")
)

edges <- data.frame(
  from = c(1, 2, 3, 2),
  to = c(2, 3, 4, 4)
)

ggplot() +
  # Add edges
  geom_segment(data = edges, 
               aes(x = nodes$x[from], y = nodes$y[from],
                   xend = nodes$x[to], yend = nodes$y[to]),
               arrow = arrow(length = unit(0.3, "cm")),
               color = "#4287f5", size = 1.2) +
  # Add nodes
  geom_point(data = nodes, aes(x, y), size = 20, color = "#f5a742") +
  # Add labels
  geom_text(data = nodes, aes(x, y, label = label), fontface = "bold") +
  theme_void() +
  coord_fixed() +
  labs(title = "Project Approach") +
  theme(
    plot.margin = margin(20, 20, 20, 20),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
  )
```

## GlobalDrive Automotive Profile

```{r company-profile}
# Create data for company profile visualization
goals <- data.frame(
  goal = c("Manufacturing Cost Reduction", "Quality Improvement", 
           "Time-to-Market Acceleration", "Carbon Neutrality", 
           "Electric Vehicle Transition"),
  target = c(15, 30, 40, 100, 60),
  category = c("Efficiency", "Efficiency", "Efficiency", 
               "Sustainability", "Sustainability")
)

# Goal visualization
ggplot(goals, aes(x = reorder(goal, target), y = target, fill = category)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_text(aes(label = paste0(target, "%")), 
            position = position_stack(vjust = 0.5),
            color = "white", fontface = "bold", size = 5) +
  coord_flip() +
  scale_fill_manual(values = c("Efficiency" = "#4287f5", "Sustainability" = "#42f584")) +
  labs(
    title = "GlobalDrive Strategic Goals",
    subtitle = "5-Year Targets",
    x = NULL,
    y = "Target Percentage"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 12, face = "bold"),
    axis.text.x = element_text(size = 10),
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12),
    legend.title = element_blank(),
    legend.position = "bottom"
  )
```

- Global manufacturer with facilities in North America, Europe, and Asia
- 3 million+ vehicles annually across multiple brands
- Digital transformation is a key strategic priority

::: {.notes}
- GlobalDrive is a fictional multinational automotive manufacturer
- They produce over 3 million vehicles across three continents
- Strategic goals include major cost reductions and quality improvements
- They're also committed to sustainability with carbon neutrality by 2030
- Digital transformation, particularly AI adoption, is critical to these goals
:::

## Current AI Infrastructure & Challenges

::: {layout="[[1,1]]"}
**Current Infrastructure**:

- Fragmented approach across business units
- Limited on-premises GPU servers
- Ad-hoc cloud usage across multiple providers
- Minimal edge computing capabilities
- Legacy manufacturing systems with limited connectivity

```{r challenges-radar}
# Create infrastructure challenges visualization
challenges <- data.frame(
  challenge = c("High Latency", "Limited Scalability", 
                "Data Silos", "Compliance Concerns", 
                "Inconsistent Performance"),
  impact = c(9, 7, 8, 6, 8),
  priority = c("High", "Medium", "High", "Medium", "High")
)

ggplot(challenges, aes(x = challenge, y = impact, fill = priority)) +
  geom_bar(stat = "identity", width = 0.6) +
  coord_polar(start = 0) +
  scale_fill_manual(values = c("High" = "#f54242", "Medium" = "#f5a742")) +
  labs(
    title = "Key Challenges",
    subtitle = "Impact Assessment (1-10 Scale)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(face = "bold"),
    axis.text.y = element_blank(),
    axis.title = element_blank(),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    legend.position = "bottom"
  )
```
:::

::: {.notes}
- Current infrastructure has evolved organically rather than strategically
- No central governance has led to fragmented solutions
- High latency in cloud-based inference applications is a critical issue
- Data silos prevent cross-functional AI applications
- Limited edge computing capabilities restrict real-time applications
- These challenges directly impact the company's ability to leverage AI effectively
:::

## Specialized Computing Architectures

```{r hardware-comparison}
# Create data for hardware comparison
hardware <- data.frame(
  architecture = rep(c("GPUs", "TPUs", "FPGAs", "Neuromorphic"), each = 4),
  metric = rep(c("Performance", "Energy Efficiency", "Flexibility", "Cost Efficiency"), 4),
  score = c(
    # GPUs
    9, 6, 8, 7,
    # TPUs 
    10, 8, 5, 8,
    # FPGAs
    7, 8, 9, 6,
    # Neuromorphic
    6, 10, 7, 8
  )
)

# Add grouping for facets
hardware$architecture <- factor(hardware$architecture, 
                                levels = c("GPUs", "TPUs", "FPGAs", "Neuromorphic"))

ggplot(hardware, aes(x = metric, y = score, fill = architecture)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  facet_wrap(~ architecture, nrow = 1) +
  scale_fill_manual(values = c(
    "GPUs" = "#4287f5", 
    "TPUs" = "#42f584",
    "FPGAs" = "#f5a742",
    "Neuromorphic" = "#f542cb"
  )) +
  labs(
    title = "Computing Architecture Comparison",
    subtitle = "Performance Metrics (1-10 Scale)",
    y = "Score"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title.x = element_blank(),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "none",
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12)
  )
```

| Architecture | Best Applications |
|--------------|-------------------|
| **GPUs** | Training, flexible workloads, computer vision |
| **TPUs** | High-volume inference, TensorFlow pipelines |
| **FPGAs** | Real-time control, safety-critical systems |
| **Neuromorphic** | Ultra-low power monitoring, sensor networks |

::: {.notes}
- Each computing architecture has specific strengths for different AI workloads
- GPUs provide exceptional flexibility and are ideal for model training
- TPUs excel at inference workloads when using TensorFlow
- FPGAs offer deterministic performance for safety-critical applications
- Neuromorphic computing shows promise for ultra-low power edge applications
- Our approach is to match specific workloads to the most appropriate hardware
:::

## AI Applications in Automotive Manufacturing

```{r ai-applications}
# Simplified visualization to replace igraph/ggraph
# Create a simpler bubble chart instead of a network graph
ai_apps <- data.frame(
  name = c(
    "Predictive Maintenance", "Driver Assistance", "Voice Control",
    "Quality Inspection", "Robotics", "Safety Monitoring",
    "Supply Chain", "Demand Forecasting", "Energy Management",
    "Virtual Prototyping", "Simulation", "Generative Design"
  ),
  category = c(
    rep("In-Vehicle", 3),
    rep("Factory Floor", 3),
    rep("Enterprise", 3),
    rep("Design", 3)
  ),
  importance = c(20, 18, 15, 25, 20, 15, 18, 15, 15, 20, 18, 15),
  x = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3),
  y = c(4, 4, 4, 3, 3, 3, 2, 2, 2, 1, 1, 1)
)

ggplot(ai_apps, aes(x = x, y = y, size = importance, color = category)) +
  geom_point(alpha = 0.7) +
  geom_text(aes(label = name), size = 3, vjust = -1.5) +
  scale_color_manual(values = c(
    "In-Vehicle" = "#4287f5",
    "Factory Floor" = "#f5a742",
    "Enterprise" = "#42f584",
    "Design" = "#f542cb"
  )) +
  scale_size_continuous(range = c(5, 15)) +
  labs(
    title = "AI Applications Across the Value Chain",
    subtitle = "Key Use Cases by Category"
  ) +
  theme_void() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12),
    legend.title = element_blank()
  ) +
  guides(size = "none")
```

- **In-Vehicle**: Predictive maintenance, driver assistance, autonomous features
- **Factory Floor**: Visual inspection, robotics, real-time monitoring
- **Enterprise**: Supply chain optimization, demand forecasting, energy management
- **Design**: Virtual prototyping, simulation, generative design

::: {.notes}
- AI applications span the entire automotive value chain
- In-vehicle systems include predictive maintenance and driver assistance
- Factory floor applications focus on quality inspection and robotics
- Enterprise applications optimize supply chain and operations
- Design applications accelerate product development
- Each application domain has different computing requirements
- The bubble chart shows key use cases by category
:::

## Proposed Hybrid Cloud-Edge Architecture

```{r architecture-diagram}
# Create architecture layers data
architecture_data <- data.frame(
  Layer = c("Cloud", "Cloud", "Edge", "Edge", "Middleware", "Middleware", "Network", "Network", "Monitoring", "Monitoring"),
  Component = c("Model Training Platform", "Analytics Platform", "Inference Hardware", "Sensor Interface", 
                "Containerization", "Orchestration", "Messaging", "Security", "Telemetry", "Visualization"),
  y_position = c(10, 9, 7, 6, 4, 3, 2, 1, 8, 5)
)

# Create a color palette for the layers
layer_colors <- c(
  "Cloud" = "#4287f5",       # Blue
  "Edge" = "#42f584",        # Green
  "Middleware" = "#f5a742",  # Orange
  "Network" = "#f542cb",     # Pink
  "Monitoring" = "#f5dc42"   # Yellow
)

# Create a diagram showing data flow between components
flow_data <- data.frame(
  x = c(1, 1, 1, 1, 1.5, 1.5, 1.5),
  y = c(9.5, 7.5, 6.5, 3.5, 9.5, 6.5, 3.5),
  xend = c(1, 1, 1.5, 1.5, 1.5, 1.5, 1),
  yend = c(7.5, 3.5, 9.5, 6.5, 6.5, 3.5, 2),
  group = c(1, 2, 3, 4, 5, 6, 7)
)

ggplot() +
  geom_segment(data = flow_data, 
               aes(x = x, y = y, xend = xend, yend = yend, group = group),
               arrow = arrow(length = unit(0.2, "cm")), 
               size = 1, 
               color = "darkgrey") +
  geom_tile(data = architecture_data, 
            aes(x = 1, y = y_position, fill = Layer),
            width = 0.9, height = 0.9) +
  geom_text(data = architecture_data, 
            aes(x = 1, y = y_position, label = Component), 
            fontface = "bold", color = "white", size = 3.5) +
  scale_fill_manual(values = layer_colors) +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    legend.position = "bottom"
  ) +
  labs(
    title = "Hybrid Cloud-Edge Architecture",
    subtitle = "Component Relationships & Data Flow",
    fill = "Architecture Layer"
  ) +
  coord_fixed(ratio = 1)
```

**Key Design Principles**:
- Workload-appropriate computing placement
- Seamless data flow between edge and cloud
- Containerized deployment for consistency
- Comprehensive security across all layers
- Modular design for future expansion

::: {.notes}
- Our architecture combines cloud and edge computing in a hybrid approach
- Cloud layer handles resource-intensive workloads like model training
- Edge layer enables real-time processing at the factory floor
- Middleware provides consistent deployment and orchestration
- Network layer ensures secure, reliable communication
- Monitoring provides visibility into system performance
- Arrows represent bidirectional data flow between components
- This architecture balances performance, cost, and operational requirements
:::

## Cloud vs. Edge Computing Balance

::: {layout="[[1,1]]"}
```{r cloud-edge-comparison}
# Data for cloud vs edge comparison
compute_data <- data.frame(
  metric = c("Processing Power", "Latency", "Storage", "Energy Efficiency", "Scalability"),
  cloud = c(10, 4, 10, 5, 10),
  edge = c(6, 10, 5, 9, 6)
)

# Convert to long format for ggplot
compute_long <- compute_data %>%
  tidyr::pivot_longer(cols = c(cloud, edge), names_to = "location", values_to = "score")

# Create a simple bar chart instead of radar chart
ggplot(compute_long, aes(x = metric, y = score, fill = location)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("cloud" = "#4287f5", "edge" = "#42f584")) +
  labs(
    title = "Cloud vs. Edge Capabilities",
    subtitle = "Performance Metrics (1-10 Scale)",
    y = "Score (1-10)",
    x = NULL,
    fill = "Computing Location"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    legend.position = "bottom"
  )
```

**Work Distribution**:

**Cloud Optimal For**:
- Model training on large datasets
- Centralized analytics and reporting
- Global coordination across facilities
- Long-term data storage and backup

**Edge Optimal For**:
- Real-time inference (quality inspection)
- Local data preprocessing and filtering
- Privacy-sensitive operations
- Continuous operation during outages

> **Key Insight**: The hybrid approach combines strengths while mitigating weaknesses.
:::

::: {.notes}
- Cloud computing excels at processing power, storage, and scalability
- Edge computing provides low latency and better energy efficiency
- Bar chart shows the complementary nature of these paradigms
- Workloads should be strategically placed based on requirements
- Real-time applications belong at the edge to minimize latency
- Resource-intensive training belongs in the cloud for scalability
- Our architecture leverages the strengths of both approaches
:::

## Proof of Concept Implementation

```{r poc-diagram, fig.height=6}
# Simplified diagram to replace DiagrammeR
# Create manual node positions for the diagram
nodes <- data.frame(
  name = c("Camera", "Jetson", "Alert", "CloudTraining", "CloudStorage", "CloudAnalytics"),
  label = c("Industrial\nCamera", "NVIDIA Jetson\nXavier NX", "Alert\nSystem", 
            "AWS SageMaker\nModel Training", "AWS S3\nDefect Storage", "AWS QuickSight\nAnalytics"),
  x = c(1, 2, 3, 5, 5, 5),
  y = c(2, 2, 2, 3, 2, 1),
  type = c("Edge", "Edge", "Edge", "Cloud", "Cloud", "Cloud")
)

# Define edges/connections
edges <- data.frame(
  from = c("Camera", "Jetson", "Jetson", "CloudStorage", "CloudTraining", "CloudStorage"),
  to = c("Jetson", "Alert", "CloudStorage", "CloudAnalytics", "Jetson", "CloudTraining"),
  label = c("Image Feed", "Defect\nDetection", "Defect\nMetadata", 
            "Analytics", "Model\nUpdates", "Training\nData"),
  x = c(1.5, 2.5, 3.5, 5, 3.5, 5),
  y = c(2.2, 2.2, 2.5, 1.5, 2.8, 2.5)
)

# Plot
ggplot() +
  # Add edges as arrows
  geom_segment(data = edges, 
               aes(x = nodes$x[match(from, nodes$name)], 
                   y = nodes$y[match(from, nodes$name)],
                   xend = nodes$x[match(to, nodes$name)], 
                   yend = nodes$y[match(to, nodes$name)]),
               arrow = arrow(length = unit(0.2, "cm")),
               color = "darkgrey", size = 1) +
  # Add edge labels
  geom_text(data = edges, aes(x = x, y = y, label = label), size = 3) +
  # Add node shapes  
  geom_point(data = nodes, aes(x = x, y = y, color = type), size = 18) +
  # Add node labels
  geom_text(data = nodes, aes(x = x, y = y, label = label), size = 3, fontface = "bold") +
  # Add rectangle outlines for groups
  annotate("rect", xmin = 0.5, xmax = 3.5, ymin = 0.5, ymax = 3.5, 
           color = "#42f584", fill = NA, linetype = "dashed") +
  annotate("rect", xmin = 4.5, xmax = 5.5, ymin = 0.5, ymax = 3.5, 
           color = "#4287f5", fill = NA, linetype = "dashed") +
  # Add group labels
  annotate("text", x = 2, y = 3.2, label = "Edge Environment", 
           color = "#42f584", fontface = "bold") +
  annotate("text", x = 5, y = 3.2, label = "Cloud Environment", 
           color = "#4287f5", fontface = "bold") +
  # Styling
  scale_color_manual(values = c("Edge" = "#42f584", "Cloud" = "#4287f5")) +
  theme_void() +
  theme(legend.position = "none") +
  labs(title = "Quality Inspection PoC Architecture") +
  coord_fixed()
```

**Quality Inspection Use Case**:

- Camera system on assembly line detecting defects
- NVIDIA Jetson Xavier NX hardware at the edge
- YOLOv5 model optimized with TensorRT
- Cloud training with AWS SageMaker
- Comprehensive testing framework with clear metrics
- A/B testing against current cloud-only solution

::: {.notes}
- We selected quality inspection as our first proof-of-concept use case
- The PoC implements a hybrid approach with edge inference and cloud training
- Camera system captures real-time images of components on the assembly line
- Jetson Xavier processes images locally for immediate defect detection
- Only defect metadata and images are sent to the cloud for storage
- Cloud provides model training and analytics capabilities
- The system was tested against the current cloud-only solution
- This architecture demonstrates all key principles of our approach
:::

## PoC Evaluation Framework

```{r evaluation-framework}
# Performance metrics data
metrics <- data.frame(
  category = rep(c("Performance", "Reliability", "Operational", "Business"), each = 3),
  metric = c(
    "Inference Latency", "Detection Accuracy", "Throughput",
    "Uptime", "Recovery Time", "Data Consistency",
    "Integration Complexity", "Training Time", "Update Time",
    "Defect Escape Rate", "Cost Savings", "Production Impact"
  ),
  target = c(
    "<30ms", ">98%", ">30 FPS",
    ">99.9%", "<30s", "100%",
    "<120 hours", "<4 hours", "<15 min",
    "-40%", "+$650K/yr", "No disruption"
  ),
  importance = c(
    10, 9, 8,
    9, 7, 8,
    6, 5, 7,
    10, 9, 8
  )
)

# Set factor levels for ordering
metrics$category <- factor(metrics$category, levels = c("Performance", "Reliability", "Operational", "Business"))

# Create colors for categories
category_colors <- c(
  "Performance" = "#4287f5",
  "Reliability" = "#42f584",
  "Operational" = "#f5a742",
  "Business" = "#f542cb"
)

# Create a heatmap-style visualization
ggplot(metrics, aes(x = reorder(metric, -importance), y = "Target", fill = category)) +
  geom_tile(color = "white", size = 0.5) +
  geom_text(aes(label = target), fontface = "bold", size = 3.5) +
  facet_grid(. ~ category, scales = "free_x", space = "free_x") +
  scale_fill_manual(values = category_colors) +
  labs(
    title = "PoC Evaluation Framework",
    subtitle = "Key Metrics and Target Values"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_blank(),
    axis.title = element_blank(),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "none",
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12),
    panel.grid = element_blank()
  )
```

**Testing Methodology**:
- A/B testing against current solution
- Performance baselining before implementation
- Synthetic load testing for performance boundaries
- Fault injection for resilience assessment
- Statistical significance testing (p<0.01)

::: {.notes}
- We established a comprehensive evaluation framework with four categories
- Performance metrics focus on speed and accuracy of AI processing
- Reliability metrics ensure the system operates consistently
- Operational metrics address ease of integration and maintenance
- Business metrics quantify the financial and production impact
- Clear target values were established for each metric before testing
- Multiple testing methodologies were employed to ensure thorough evaluation
- This framework enables objective assessment of the PoC's success
:::

## Performance Results

```{r performance-results}
# Results data
results <- data.frame(
  metric = c("Inference Latency", "Detection Accuracy", "False Positive Rate", "Bandwidth Usage", "Cloud Compute Cost"),
  before = c(320, 94.2, 3.0, 3500, 1200),
  after = c(27, 98.7, 1.2, 75, 320),
  unit = c("ms", "%", "%", "MB/hr", "K$/yr")
)

# Calculate improvement
results <- results %>%
  mutate(
    improvement = case_when(
      metric == "Inference Latency" ~ (before - after) / before * 100,
      metric == "Detection Accuracy" ~ (after - before),
      metric == "False Positive Rate" ~ (before - after) / before * 100,
      metric == "Bandwidth Usage" ~ (before - after) / before * 100,
      metric == "Cloud Compute Cost" ~ (before - after) / before * 100
    ),
    better = case_when(
      metric == "Detection Accuracy" ~ "higher",
      TRUE ~ "lower"
    ),
    imp_label = case_when(
      metric == "Detection Accuracy" ~ paste0("+", round(improvement, 1), " pts"),
      TRUE ~ paste0(round(improvement, 1), "%")
    )
  )

# Convert to long format for plotting
results_long <- results %>%
  select(metric, before, after, unit) %>%
  tidyr::pivot_longer(cols = c(before, after), names_to = "time", values_to = "value")

# Create the bar chart
ggplot(results_long, aes(x = metric, y = value, fill = time)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
  geom_text(aes(label = paste0(value, " ", unit)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  geom_text(data = results, aes(x = metric, y = 0, label = imp_label),
            position = position_dodge(width = 0.9),
            vjust = -0.5, hjust = 0.5, size = 4, fontface = "bold", color = "#f54242") +
  scale_fill_manual(values = c("before" = "#f5a742", "after" = "#42f584"),
                   labels = c("Before (Cloud-Only)", "After (Hybrid)")) +
  labs(
    title = "Performance Improvements from Hybrid Architecture",
    subtitle = "Key Metrics Before and After Implementation",
    fill = NULL
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10, face = "bold"),
    axis.title = element_blank(),
    legend.position = "top",
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12)
  )
```

::: {.notes}
- Our PoC demonstrated significant improvements across all key metrics
- Inference latency was reduced by over 90% (320ms to 27ms)
- Detection accuracy increased to 98.7% (4.5 percentage point improvement)
- False positive rate was reduced by 60%
- Bandwidth usage decreased by over 95%
- Cloud computing costs were reduced by 73%
- All improvements were statistically significant (p<0.01)
- These results validate the effectiveness of our hybrid approach
:::

## Return on Investment

::: {layout="[[1,1]]"}
```{r roi-analysis}
# ROI data
months <- 0:24
initial_investment <- 800000  # $800K initial investment

# Monthly savings
monthly_savings <- 200000 / 12  # $200K annual savings / 12

# Cumulative savings over time
cumulative_savings <- monthly_savings * months

# Net ROI
net_roi <- cumulative_savings - initial_investment

# Create data frame
roi_data <- data.frame(
  month = months,
  investment = initial_investment,
  savings = cumulative_savings,
  net = net_roi
)

# Find the breakeven point
breakeven_month <- min(which(roi_data$net >= 0))

# Plot
ggplot(roi_data, aes(x = month)) +
  geom_line(aes(y = investment, color = "Investment"), size = 1.2) +
  geom_line(aes(y = savings, color = "Cumulative Savings"), size = 1.2) +
  geom_line(aes(y = net, color = "Net ROI"), size = 1.5) +
  geom_vline(xintercept = breakeven_month, linetype = "dashed", color = "darkgrey") +
  geom_text(aes(x = breakeven_month + 1, y = 0, 
                label = paste("Breakeven at", breakeven_month, "months")),
            hjust = 0, vjust = -1, size = 3.5) +
  scale_color_manual(values = c(
    "Investment" = "#f5a742",
    "Cumulative Savings" = "#42f584",
    "Net ROI" = "#4287f5"
  )) +
  scale_y_continuous(labels = scales::dollar_format(scale = 1/1000, suffix = "K")) +
  labs(
    title = "ROI Analysis",
    subtitle = "Investment vs. Savings Over Time",
    x = "Month",
    y = "Amount ($)",
    color = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position = "top",
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12)
  )
```

**Cost Analysis**:

- Edge hardware: $600-800 per device
- Deployment engineering: ~120 hours per line
- Cloud cost reduction: $880K annually
- Network savings: $300-450K annually

**Business Value**:
- Defect escape rate reduced by 58%
- Quality improvement savings: $1.2M per line
- ROI timeline: 9.3 month payback
- 5-year projected savings: $13.5M
:::
::: {.notes}
- Our ROI analysis shows a compelling business case for the proposed architecture
- Initial investment includes hardware, engineering time, and training
- Savings come from reduced cloud costs, bandwidth, and quality improvements
- The breakeven point occurs at approximately 9.3 months
- The defect escape rate reduction delivers the largest financial impact
- Quality improvements translate directly to bottom-line savings
- The 5-year projected savings of $13.5M represent a significant return
- This ROI justifies the investment and supports the implementation roadmap
:::

## Implementation Roadmap

```{r roadmap}
# Create roadmap data
roadmap <- data.frame(
  phase = c("Phase 1: Infrastructure Audit", 
            "Phase 2: Use Case Selection",
            "Phase 3: PoC Development",
            "Phase 4: Pilot Rollout",
            "Phase 5: Enterprise Deployment"),
  start_month = c(1, 3, 4, 6, 9),
  duration = c(2, 1, 2, 3, 10),
  color = c("#4287f5", "#42f584", "#f5a742", "#f542cb", "#f5dc42")
)

# Add end month
roadmap$end_month <- roadmap$start_month + roadmap$duration

# Add milestone data points
milestones <- data.frame(
  phase = c("Phase 1", "Phase 2", "Phase 3", "Phase 4", "Phase 5"),
  month = c(3, 4, 6, 9, 19),
  milestone = c("Baseline Report", "Selected Use Cases", "Working Prototype", "Pilot Results", "Full Deployment"),
  color = roadmap$color
)

# Plot the roadmap
ggplot() +
  # Add phase bars
  geom_segment(data = roadmap, 
               aes(x = start_month, xend = end_month, 
                   y = factor(phase, levels = rev(phase)), yend = factor(phase, levels = rev(phase)), 
                   color = phase),
               size = 10, alpha = 0.7) +
  # Add milestone points
  geom_point(data = milestones, 
             aes(x = month, y = factor(phase, levels = rev(roadmap$phase)), color = phase),
             size = 4) +
  # Add milestone labels
  geom_text(data = milestones,
            aes(x = month, y = factor(phase, levels = rev(roadmap$phase)), 
                label = milestone, color = phase),
            hjust = -0.1, vjust = -1, fontface = "bold", size = 3) +
  # Customize scales and labels
  scale_color_manual(values = setNames(roadmap$color, roadmap$phase)) +
  scale_x_continuous(breaks = seq(0, 20, 2), 
                    labels = paste("Month", seq(0, 20, 2)),
                    limits = c(0, 20)) +
  labs(
    title = "Implementation Roadmap",
    subtitle = "Phased Approach with Key Milestones",
    x = NULL,
    y = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.text.y = element_text(size = 10, face = "bold"),
    panel.grid.minor = element_blank()
  )
```

**Phased Implementation**:
1. Infrastructure audit & baseline assessment (2 months)
2. High-impact use case selection (1 month)
3. Prototype & PoC development (2 months)
4. Pilot rollout & evaluation (3 months)
5. Enterprise-scale deployment (10 months)

::: {.notes}
- We recommend a phased implementation approach over 18 months
- Phase 1 establishes baselines and documents current infrastructure
- Phase 2 identifies high-impact, low-risk use cases for initial deployment
- Phase 3 develops and tests the prototype in a controlled environment
- Phase 4 deploys and evaluates the solution in a production setting
- Phase 5 scales the architecture across all facilities and use cases
- Each phase has clear deliverables and builds on previous phases
- This approach balances quick wins with long-term transformation
- The timeline allows for learning and adjustment throughout implementation
:::

## Key Recommendations

::: {layout="[[1,1]]"}
```{r recommendations}
# Create recommendation data
recommendations <- data.frame(
  id = 1:7,
  recommendation = c(
    "Begin infrastructure audit immediately",
    "Prioritize quality inspection & predictive maintenance",
    "Standardize edge computing platforms",
    "Develop internal AI expertise",
    "Establish AI governance framework",
    "Create operations-AI feedback loop",
    "Measure & communicate business impact"
  ),
  priority = c("High", "High", "Medium", "Medium", "Medium", "High", "High"),
  x_pos = c(1, 2, 3, 4, 3, 2, 1),
  y_pos = c(4, 3, 2, 1, 0, -1, -2)
)

# Create a priority color scale
priority_colors <- c(
  "High" = "#f54242",
  "Medium" = "#f5a742"
)

# Create a network diagram
ggplot(recommendations, aes(x = x_pos, y = y_pos)) +
  # Add connections
  geom_segment(x = 1, y = 4, xend = 2, yend = 3, color = "gray70") +
  geom_segment(x = 2, y = 3, xend = 3, yend = 2, color = "gray70") +
  geom_segment(x = 3, y = 2, xend = 4, yend = 1, color = "gray70") +
  geom_segment(x = 4, y = 1, xend = 3, yend = 0, color = "gray70") +
  geom_segment(x = 3, y = 0, xend = 2, yend = -1, color = "gray70") +
  geom_segment(x = 2, y = -1, xend = 1, yend = -2, color = "gray70") +
  # Add points
  geom_point(aes(color = priority), size = 18, alpha = 0.8) +
  # Add labels
  geom_text(aes(label = id), color = "white", fontface = "bold", size = 6) +
  # Configure colors and theme
  scale_color_manual(values = priority_colors) +
  theme_void() +
  labs(
    title = "Implementation Sequence",
    color = "Priority"
  ) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  )
```

1. Begin infrastructure audit immediately
2. Prioritize quality inspection & predictive maintenance
3. Standardize edge computing platforms
4. Develop internal AI expertise
5. Establish AI governance framework
6. Create operations-AI feedback loop
7. Measure & communicate business impact

**Critical Success Factors**:
- Executive sponsorship
- Cross-functional team involvement
- Incremental implementation approach
- Continuous measurement and refinement
:::

::: {.notes}
- Our key recommendations provide a roadmap for success
- Begin with a comprehensive infrastructure audit to establish baselines
- Quality inspection and predictive maintenance offer the highest ROI potential
- Standardized edge computing platforms reduce complexity and maintenance costs
- Internal AI expertise development is critical for long-term success
- AI governance ensures consistent quality and compliance
- A feedback loop between operations and AI development drives continuous improvement
- Regular measurement and communication builds organizational support
- Executive sponsorship is essential to drive change across the organization
:::

## Conclusion

::: {layout="[[1,1]]"}
**Key Takeaways**:

- Hybrid cloud-edge architecture optimizes AI workloads
- Strategic hardware selection based on workload requirements
- PoC validates performance and cost improvements
- Phased implementation balances quick wins with transformation
- Clear ROI with 9.3 month payback period

**Next Steps**:
- Executive approval for Phase 1
- Resource allocation for implementation
- Selection of pilot manufacturing facility

```{r conclusion-chart}
# Create a final summary visualization
# Create data for the summary spider chart
summary_data <- data.frame(
  dimension = c("Performance", "Cost Efficiency", "Scalability", "Security", "Flexibility"),
  score = c(9.2, 8.7, 8.5, 9.0, 8.8)
)

# Calculate coordinates for radar chart
n_dim <- nrow(summary_data)
angles <- 2*pi * (0:(n_dim))/n_dim
summary_data_plot <- summary_data %>%
  mutate(
    angle = 2*pi * (0:(n_dim-1))/n_dim,
    x = score * sin(angle),
    y = score * cos(angle)
  )

# Add the first point at the end to close the polygon
summary_data_closed <- rbind(
  summary_data_plot,
  summary_data_plot[1,]
)

# Calculate points for the reference circles
create_circle_points <- function(radius) {
  angles <- seq(0, 2*pi, length.out = 100)
  data.frame(
    x = radius * sin(angles),
    y = radius * cos(angles),
    radius = radius
  )
}

# Create circles for different score levels
circles <- rbind(
  create_circle_points(5),
  create_circle_points(7),
  create_circle_points(10)
)

# Plot
ggplot() +
  # Add reference circles
  geom_path(data = circles, aes(x = x, y = y, group = radius), 
            color = "gray80", linetype = "dashed", size = 0.5) +
  # Add reference labels
  geom_text(data = data.frame(x = 0, y = c(5, 7, 10), label = c("5", "7", "10")),
            aes(x = x, y = y, label = label), 
            color = "gray50", size = 3, hjust = -0.5) +
  # Add dimension lines
  geom_segment(data = data.frame(x = 0, y = 0, 
                                 xend = 11 * sin(summary_data_plot$angle), 
                                 yend = 11 * cos(summary_data_plot$angle)),
               aes(x = x, y = y, xend = xend, yend = yend),
               color = "gray70", linetype = "dotted") +
  # Add polygon
  geom_polygon(data = summary_data_closed, 
               aes(x = x, y = y), 
               fill = "#4287f5", alpha = 0.5) +
  # Add outline
  geom_path(data = summary_data_closed, 
            aes(x = x, y = y), 
            color = "#4287f5", size = 1.5) +
  # Add points
  geom_point(data = summary_data_plot, 
             aes(x = x, y = y), 
             color = "#4287f5", size = 4) +
  # Add dimension labels
  geom_text(data = data.frame(
              dimension = summary_data$dimension,
              x = 12 * sin(summary_data_plot$angle),
              y = 12 * cos(summary_data_plot$angle)
            ),
            aes(x = x, y = y, label = dimension),
            fontface = "bold", size = 4,
            hjust = ifelse(sin(summary_data_plot$angle) < 0, 1, 0),
            vjust = ifelse(cos(summary_data_plot$angle) < 0, 0, 1)) +
  # Add score labels
  geom_text(data = summary_data_plot,
            aes(x = x, y = y, label = score),
            color = "white", fontface = "bold", size = 3,
            nudge_x = 0.3 * sin(summary_data_plot$angle),
            nudge_y = 0.3 * cos(summary_data_plot$angle)) +
  # Configure theme
  coord_fixed() +
  theme_void() +
  labs(
    title = "Solution Evaluation",
    subtitle = "Score (1-10 Scale)"
  ) +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5)
  )
```
:::

::: {.notes}
- Our hybrid cloud-edge architecture provides a comprehensive solution for GlobalDrive
- The architecture balances performance, cost, security, and flexibility
- We've validated the approach through a detailed proof-of-concept
- The proposed implementation roadmap offers a practical path forward
- The business case is compelling with a clear ROI and short payback period
- GlobalDrive is well-positioned to leverage AI for competitive advantage
- The next steps focus on securing executive approval and resource allocation
- Starting with the infrastructure audit provides immediate value with minimal risk
:::

## Thank You & Questions

::: {layout="[[1,1]]"}
**Team Members**:
- Bogdan Bancescu
- Tim Nicholas Döring
- Charles Watson Ndethi Kibaki

**Contact Information**:  
team_contact@email.com

**We welcome your questions and feedback on our proposed approach.**

```{r wordcloud, message=FALSE, warning=FALSE}
# Replace wordcloud with a simple horizontal bar chart of key terms
key_terms <- data.frame(
  term = c("Hybrid Architecture", "Edge Computing", "Cloud Training", 
           "GPUs", "TPUs", "Real-time Inference", 
           "Quality Inspection", "Predictive Maintenance",
           "ROI", "Scalability", "Performance", "Security"),
  freq = c(20, 18, 15, 12, 10, 17, 16, 14, 13, 11, 19, 9)
)

# Create a horizontal bar chart
ggplot(key_terms, aes(x = reorder(term, freq), y = freq, fill = freq)) +
  geom_bar(stat = "identity", width = 0.7) +
  coord_flip() +
  scale_fill_gradient(low = "#4287f5", high = "#f542cb", guide = "none") +
  labs(
    title = "Key Concepts in Our Solution",
    x = NULL,
    y = NULL
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 12, face = "bold"),
    axis.text.x = element_blank(),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  )
```
:::

::: {.notes}
- Thank the audience for their time and attention
- Recap the key benefits of our proposed solution
- Highlight our team's expertise and commitment to this project
- Be prepared to answer questions on technical details, implementation, and ROI
- For specific technical questions, refer to the report for more detailed information
- Emphasize our availability for follow-up discussions and next steps
:::