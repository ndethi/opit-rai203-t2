{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit Pet Breed Similarity Search App\n",
    "\n",
    "This Streamlit application allows users to upload a pet image and find similar-looking pets from a pre-loaded database using a trained deep metric learning model.\n",
    "\n",
    "## Running the Streamlit App\n",
    "\n",
    "To run this Streamlit app:\n",
    "1. Ensure you have the necessary Python packages installed (`streamlit`, `torch`, `torchvision`, `Pillow`, `numpy`, `tqdm`).\n",
    "2. Make sure you have the trained model file (e.g., `pet_metric_learning_resnet18_triplet.pth`) and the pet image database (e.g., `./data/oxford-iiit-pet/images`) available in the correct paths relative to where you run the command. You can configure these paths in the application's sidebar.\n",
    "3. Open your terminal in the directory containing this notebook.\n",
    "4. Convert this notebook to a Python script: `jupyter nbconvert --to python streamlit_pet_similarity_app.ipynb`\n",
    "5. Run the command: `streamlit run streamlit_pet_similarity_app.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pet Similarity Search - Streamlit Application\n",
    "\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm # Added for progress bar during database loading\n",
    "\n",
    "# Define the EmbeddingNet class here (copied from the notebook)\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet18', embedding_size=128, pretrained=True):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "\n",
    "        # Load the pretrained backbone model\n",
    "        if backbone_name == 'resnet18':\n",
    "            self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)\n",
    "            backbone_output_size = 512\n",
    "        elif backbone_name == 'resnet50':\n",
    "            self.backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT if pretrained else None)\n",
    "            backbone_output_size = 2048\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {backbone_name}\")\n",
    "\n",
    "        # Remove the classification layer\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n",
    "\n",
    "        # Projection head (MLP)\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(backbone_output_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        embeddings = self.projection_head(features)\n",
    "\n",
    "        # Normalize embeddings to unit length (important for cosine distance)\n",
    "        normalized_embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "        return normalized_embeddings\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "# Load the trained model\n",
    "@st.cache_resource\n",
    "def load_model(model_path='pet_metric_learning_resnet18_triplet.pth'):\n",
    "    if not os.path.exists(model_path):\n",
    "        st.error(f\"Model file not found at {model_path}. Please ensure the trained model is in the correct location.\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "        model = EmbeddingNet(\n",
    "            backbone_name=checkpoint.get('backbone_name', 'resnet18'), # Default if not found\n",
    "            embedding_size=checkpoint.get('embedding_size', 128),     # Default if not found\n",
    "            pretrained=False # Important: Load weights, don't re-download pretrained\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "\n",
    "        class_mapping = checkpoint.get('class_mapping', {'idx_to_class': {}}) # Default if not found\n",
    "\n",
    "        return model, class_mapping\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Preprocessing transformation\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Function to compute embedding for an image\n",
    "def get_embedding(model, image):\n",
    "    transform = get_transform()\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding = model(image_tensor)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "# Function to find similar pets in the database\n",
    "def find_similar_pets(query_embedding, database_embeddings, database_images, database_labels, top_k=5):\n",
    "    if database_embeddings is None or len(database_embeddings) == 0:\n",
    "        return [], [], []\n",
    "    # Compute cosine similarity\n",
    "    similarity = torch.matmul(query_embedding, database_embeddings.T)\n",
    "\n",
    "    # Get top-k indices\n",
    "    # Ensure k is not larger than the number of items in the database\n",
    "    actual_k = min(top_k, len(database_labels))\n",
    "    if actual_k == 0:\n",
    "        return [], [], []\n",
    "\n",
    "    similarity_scores, indices = torch.topk(similarity, k=actual_k)\n",
    "    indices = indices.squeeze().tolist()\n",
    "    similarity_scores = similarity_scores.squeeze().tolist()\n",
    "\n",
    "    # Handle case where k=1 or only one result\n",
    "    if not isinstance(indices, list):\n",
    "        indices = [indices]\n",
    "        similarity_scores = [similarity_scores]\n",
    "\n",
    "    # Return top-k similar images and their labels\n",
    "    similar_images = [database_images[i] for i in indices]\n",
    "    similar_labels = [database_labels[i] for i in indices]\n",
    "    similarities = similarity_scores\n",
    "\n",
    "    return similar_images, similar_labels, similarities\n",
    "\n",
    "# Load database images and compute embeddings\n",
    "@st.cache_data # Cache the loaded data\n",
    "def load_database(directory, _model): # Pass model explicitly to ensure cache invalidation if model changes\n",
    "    transform = get_transform()\n",
    "    image_files = []\n",
    "    # Look for images in subdirectories as well (common in datasets)\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "\n",
    "    images = []\n",
    "    file_paths = []\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    # Limit database size for demo performance\n",
    "    max_db_size = 500\n",
    "    image_files = image_files[:max_db_size]\n",
    "\n",
    "    st.write(f\"Found {len(image_files)} images. Processing up to {max_db_size}...\")\n",
    "    progress_bar = st.progress(0)\n",
    "\n",
    "    for i, img_path in enumerate(tqdm(image_files, desc=\"Loading Database\")):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            images.append(img)\n",
    "            file_paths.append(img_path)\n",
    "\n",
    "            # Compute embedding\n",
    "            img_tensor = transform(img).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                embedding = _model(img_tensor)\n",
    "            embeddings.append(embedding.squeeze())\n",
    "\n",
    "            # Extract label (assuming format like 'ClassName_123.jpg')\n",
    "            label = os.path.basename(img_path).split('_')[0]\n",
    "            labels.append(label)\n",
    "\n",
    "        except Exception as e:\n",
    "            # st.warning(f\"Could not process {img_path}: {e}\") # Optional: show warnings\n",
    "            continue\n",
    "        progress_bar.progress((i + 1) / len(image_files))\n",
    "\n",
    "    # Stack embeddings into a tensor\n",
    "    if embeddings:\n",
    "        embeddings_tensor = torch.stack(embeddings)\n",
    "    else:\n",
    "        embeddings_tensor = torch.tensor([])\n",
    "\n",
    "    progress_bar.empty() # Clear progress bar\n",
    "\n",
    "    return images, embeddings_tensor, labels, file_paths\n",
    "\n",
    "# Main Streamlit app\n",
    "def run_app():\n",
    "    st.set_page_config(layout=\"wide\")\n",
    "    st.title(\"ðŸ¾ Pet Breed Similarity Search ðŸ¾\")\n",
    "    st.write(\"Upload a pet image to find similar-looking pets in our database!\")\n",
    "\n",
    "    # --- Sidebar for Configuration ---\n",
    "    st.sidebar.header(\"Configuration\")\n",
    "    model_file = st.sidebar.text_input(\"Model File Path\", \"pet_metric_learning_resnet18_triplet.pth\")\n",
    "    database_dir = st.sidebar.text_input(\"Database Directory Path\", \"./data/oxford-iiit-pet/images\") # Default to common location\n",
    "    top_k_similar = st.sidebar.slider(\"Number of Similar Pets to Show\", 1, 10, 5)\n",
    "\n",
    "    # --- Load Model ---\n",
    "    model, class_mapping = load_model(model_file)\n",
    "    if model is None:\n",
    "        st.stop() # Stop execution if model loading failed\n",
    "\n",
    "    idx_to_class = class_mapping.get('idx_to_class', {})\n",
    "\n",
    "    # --- Load Database ---\n",
    "    st.sidebar.header(\"Database\")\n",
    "    if st.sidebar.button(\"Load/Reload Database\"):\n",
    "        # Clear cache if reload is requested\n",
    "        st.cache_data.clear()\n",
    "        st.cache_resource.clear() # Also clear model cache if needed\n",
    "        st.experimental_rerun() # Rerun to reload with cleared cache\n",
    "\n",
    "    if not os.path.isdir(database_dir):\n",
    "        st.warning(f\"Database directory not found: '{database_dir}'. Please provide a valid path in the sidebar.\")\n",
    "        database_images, database_embeddings, database_labels, file_paths = [], torch.tensor([]), [], []\n",
    "    else:\n",
    "        with st.spinner(f\"Loading database from '{database_dir}'... This might take a while.\"):\n",
    "            # Pass model to ensure cache works correctly with the specific model instance\n",
    "            database_images, database_embeddings, database_labels, file_paths = load_database(database_dir, model)\n",
    "        if not database_images:\n",
    "            st.error(\"No images loaded from the database directory. Check the path and image files.\")\n",
    "        else:\n",
    "            st.sidebar.success(f\"Loaded {len(database_images)} images from database.\")\n",
    "\n",
    "    # --- Main Area: Query and Results ---\n",
    "    col1, col2 = st.columns([1, 2])\n",
    "\n",
    "    with col1:\n",
    "        st.header(\"Query Image\")\n",
    "        uploaded_file = st.file_uploader(\"Choose a pet image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "        if uploaded_file is not None:\n",
    "            query_image = Image.open(uploaded_file).convert('RGB')\n",
    "            st.image(query_image, caption=\"Your Query Image\", use_column_width=True)\n",
    "\n",
    "    with col2:\n",
    "        st.header(\"Similar Pets Found\")\n",
    "        if uploaded_file is not None and len(database_images) > 0:\n",
    "            if st.button(\"Find Similar Pets\"):\n",
    "                with st.spinner(\"Comparing your pet...\"):\n",
    "                    # Get embedding for query image\n",
    "                    query_embedding = get_embedding(model, query_image)\n",
    "\n",
    "                    # Find similar images\n",
    "                    similar_images, similar_labels, similarities = find_similar_pets(\n",
    "                        query_embedding, database_embeddings, database_images, database_labels, top_k=top_k_similar\n",
    "                    )\n",
    "\n",
    "                    # Display results\n",
    "                    if not similar_images:\n",
    "                        st.warning(\"Could not find any similar pets.\")\n",
    "                    else:\n",
    "                        num_results = len(similar_images)\n",
    "                        cols = st.columns(num_results)\n",
    "                        for i, (img, label, similarity) in enumerate(zip(similar_images, similar_labels, similarities)):\n",
    "                            with cols[i]:\n",
    "                                st.image(img, caption=f\"{label.replace('_', ' ').title()}\", use_column_width=True)\n",
    "                                st.write(f\"Similarity: {similarity:.3f}\")\n",
    "        elif uploaded_file is None:\n",
    "            st.info(\"Upload an image to start the search.\")\n",
    "        elif len(database_images) == 0:\n",
    "            st.warning(\"Database is empty or not loaded. Please check the database path and click 'Load/Reload Database' in the sidebar.\")\n",
    "\n",
    "# The following check allows the script to be run directly when converted to a Python file\n",
    "if __name__ == \"__main__\":\n",
    "    run_app()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
