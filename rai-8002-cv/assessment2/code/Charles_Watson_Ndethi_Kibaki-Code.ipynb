{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment 2: Metric Learning with Oxford-IIIT Pet Dataset\n",
    "\n",
    "## Introduction and Setup\n",
    "\n",
    "This notebook implements a deep metric learning approach for the Oxford-IIIT Pet Dataset, focusing on learning an embedding space where similar pet breeds are close together and dissimilar ones are far apart. We'll explore different loss functions, evaluate the model on verification, retrieval, and few-shot classification tasks, and visualize the embedding space.\n",
    "\n",
    "### Environment Setup and Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if running in Colab (to install dependencies and set up environment)\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# Install required packages\n",
    "if IN_COLAB:\n",
    "    !pip install pytorch-metric-learning\n",
    "    !pip install faiss-gpu\n",
    "    !pip install umap-learn\n",
    "    !pip install matplotlib seaborn scikit-learn tqdm\n",
    "    !pip install gradio\n",
    "    !pip install grad-cam\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import pytorch_metric_learning\n",
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import umap\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Data Loading and Preprocessing\n",
    "\n",
    "In this section, we'll load the Oxford-IIIT Pet Dataset, perform necessary preprocessing, and create appropriate data loaders for our metric learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_oxford_pets_dataset(root=\"./data\", download=True):\n",
    "    train_val_dataset = datasets.OxfordIIITPet(\n",
    "        root=root, \n",
    "        split=\"trainval\", \n",
    "        transform=train_transform, \n",
    "        download=download\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.OxfordIIITPet(\n",
    "        root=root, \n",
    "        split=\"test\", \n",
    "        transform=eval_transform, \n",
    "        download=download\n",
    "    )\n",
    "    \n",
    "    # For evaluation, create a version of the training set with eval transforms\n",
    "    eval_train_dataset = datasets.OxfordIIITPet(\n",
    "        root=root, \n",
    "        split=\"trainval\", \n",
    "        transform=eval_transform, \n",
    "        download=False\n",
    "    )\n",
    "    \n",
    "    return train_val_dataset, test_dataset, eval_train_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Preparation for Different Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data for training, validation and few-shot evaluation\n",
    "def prepare_datasets(train_val_dataset, test_dataset, eval_train_dataset, num_holdout_classes=5, val_ratio=0.2):\n",
    "    # Get the class names\n",
    "    class_to_idx = train_val_dataset.class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    num_classes = len(class_to_idx)\n",
    "    \n",
    "    # Split classes for few-shot learning (hold out some classes for testing)\n",
    "    all_class_indices = list(range(num_classes))\n",
    "    holdout_class_indices = random.sample(all_class_indices, num_holdout_classes)\n",
    "    training_class_indices = [i for i in all_class_indices if i not in holdout_class_indices]\n",
    "    \n",
    "    holdout_classes = [idx_to_class[i] for i in holdout_class_indices]\n",
    "    print(f\"Holdout classes for few-shot learning: {holdout_classes}\")\n",
    "    \n",
    "    # Create datasets excluding holdout classes for main training\n",
    "    train_val_indices = [i for i, (_, label) in enumerate(train_val_dataset) if label not in holdout_class_indices]\n",
    "    test_indices = [i for i, (_, label) in enumerate(test_dataset) if label not in holdout_class_indices]\n",
    "    eval_train_indices = [i for i, (_, label) in enumerate(eval_train_dataset) if label not in holdout_class_indices]\n",
    "    \n",
    "    # For few-shot learning, include only holdout classes\n",
    "    few_shot_train_indices = [i for i, (_, label) in enumerate(train_val_dataset) if label in holdout_class_indices]\n",
    "    few_shot_test_indices = [i for i, (_, label) in enumerate(test_dataset) if label in holdout_class_indices]\n",
    "    \n",
    "    # Split train/val\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        train_val_indices, \n",
    "        test_size=val_ratio, \n",
    "        stratify=[train_val_dataset[i][1] for i in train_val_indices],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create Subset datasets\n",
    "    train_dataset = Subset(train_val_dataset, train_indices)\n",
    "    val_dataset = Subset(train_val_dataset, val_indices)\n",
    "    test_filtered_dataset = Subset(test_dataset, test_indices)\n",
    "    eval_train_dataset = Subset(eval_train_dataset, eval_train_indices)\n",
    "    \n",
    "    # Create datasets for few-shot learning\n",
    "    few_shot_train_dataset = Subset(train_val_dataset, few_shot_train_indices)\n",
    "    few_shot_test_dataset = Subset(test_dataset, few_shot_test_indices)\n",
    "    \n",
    "    # Create dictionary for class mapping\n",
    "    class_mapping = {\n",
    "        'class_to_idx': class_to_idx,\n",
    "        'idx_to_class': idx_to_class,\n",
    "        'holdout_class_indices': holdout_class_indices,\n",
    "        'training_class_indices': training_class_indices\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'train': train_dataset,\n",
    "        'val': val_dataset,\n",
    "        'test': test_filtered_dataset,\n",
    "        'eval_train': eval_train_dataset,\n",
    "        'few_shot_train': few_shot_train_dataset,\n",
    "        'few_shot_test': few_shot_test_dataset,\n",
    "        'class_mapping': class_mapping\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataloaders(datasets_dict, batch_size=32, num_workers=4):\n",
    "    dataloaders = {}\n",
    "    \n",
    "    for key in ['train', 'val', 'test', 'eval_train', 'few_shot_train', 'few_shot_test']:\n",
    "        if key == 'train':\n",
    "            shuffle = True\n",
    "        else:\n",
    "            shuffle = False\n",
    "            \n",
    "        dataloaders[key] = DataLoader(\n",
    "            datasets_dict[key],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    return dataloaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "train_val_dataset, test_dataset, eval_train_dataset = load_oxford_pets_dataset()\n",
    "print(f\"Train+Val size: {len(train_val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n",
    "\n",
    "# Prepare datasets for different tasks\n",
    "datasets_dict = prepare_datasets(train_val_dataset, test_dataset, eval_train_dataset)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32  # Adjust based on your GPU/memory constraints\n",
    "dataloaders = create_dataloaders(datasets_dict, batch_size=batch_size)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"\\nDataset Statistics:\")\n",
    "for key, dataloader in dataloaders.items():\n",
    "    print(f\"{key}: {len(dataloader.dataset)} samples\")\n",
    "\n",
    "class_mapping = datasets_dict['class_mapping']\n",
    "num_classes = len(class_mapping['class_to_idx'])\n",
    "print(f\"Total number of classes: {num_classes}\")\n",
    "print(f\"Number of training classes: {len(class_mapping['training_class_indices'])}\")\n",
    "print(f\"Number of few-shot classes: {len(class_mapping['holdout_class_indices'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "In this section, we'll define our metric learning model architecture using a CNN backbone and a projection head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet18', embedding_size=128, pretrained=True):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        \n",
    "        # Load the pretrained backbone model\n",
    "        if backbone_name == 'resnet18':\n",
    "            self.backbone = models.resnet18(pretrained=pretrained)\n",
    "            backbone_output_size = 512\n",
    "        elif backbone_name == 'resnet50':\n",
    "            self.backbone = models.resnet50(pretrained=pretrained)\n",
    "            backbone_output_size = 2048\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {backbone_name}\")\n",
    "        \n",
    "        # Remove the classification layer\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n",
    "        \n",
    "        # Projection head (MLP)\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(backbone_output_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        embeddings = self.projection_head(features)\n",
    "        \n",
    "        # Normalize embeddings to unit length (important for cosine distance)\n",
    "        normalized_embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "        return normalized_embeddings\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loss Function Implementation\n",
    "\n",
    "Here we'll implement several loss functions for metric learning including Triplet Loss, Contrastive Loss, and ArcFace. We'll also implement miners for efficient training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_loss_and_miner(loss_type, margin=0.2, embedding_size=128, num_classes=32):\n",
    "    \"\"\"\n",
    "    Create loss function and miner for metric learning\n",
    "    \"\"\"\n",
    "    if loss_type == 'triplet':\n",
    "        # Triplet loss with cosine distance\n",
    "        distance = distances.CosineSimilarity()\n",
    "        reducer = reducers.ThresholdReducer(low=0)\n",
    "        loss_func = losses.TripletMarginLoss(margin=margin, distance=distance, reducer=reducer)\n",
    "        mining_func = miners.TripletMarginMiner(margin=margin, distance=distance, type_of_triplets=\"semihard\")\n",
    "        \n",
    "    elif loss_type == 'contrastive':\n",
    "        # Contrastive loss\n",
    "        distance = distances.CosineSimilarity()\n",
    "        loss_func = losses.ContrastiveLoss(pos_margin=0.8, neg_margin=0.2, distance=distance)\n",
    "        mining_func = miners.PairMarginMiner(pos_margin=0.8, neg_margin=0.2, distance=distance)\n",
    "        \n",
    "    elif loss_type == 'arcface':\n",
    "        # ArcFace loss\n",
    "        loss_func = losses.ArcFaceLoss(embedding_size, num_classes, margin=28.6, scale=64)\n",
    "        mining_func = None\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported loss type: {loss_type}\")\n",
    "        \n",
    "    return loss_func, mining_func\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Hard Negative Mining (Bonus Implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HardNegativePairMiner(miners.BaseMiner):\n",
    "    def __init__(self, distance, neg_margin=0.2, hardest_fraction=0.5):\n",
    "        super().__init__()\n",
    "        self.distance = distance\n",
    "        self.neg_margin = neg_margin\n",
    "        self.hardest_fraction = hardest_fraction\n",
    "        \n",
    "    def mine(self, embeddings, labels, ref_emb=None, ref_labels=None):\n",
    "        ref_emb, ref_labels = embeddings, labels\n",
    "        dist_mat = self.distance(embeddings, ref_emb)\n",
    "        \n",
    "        # Get negative pairs (different classes)\n",
    "        negative_mask = labels.unsqueeze(1) != ref_labels.unsqueeze(0)\n",
    "        \n",
    "        # For each anchor, find all negative pairs\n",
    "        anchors, negatives = torch.where(negative_mask)\n",
    "        \n",
    "        if len(anchors) == 0:\n",
    "            return empty_tensor(0), empty_tensor(0), empty_tensor(0), empty_tensor(0)\n",
    "        \n",
    "        # Get distances for all negative pairs\n",
    "        distances = dist_mat[anchors, negatives]\n",
    "        \n",
    "        # Group by anchor\n",
    "        anchor_groups = defaultdict(list)\n",
    "        for i in range(len(anchors)):\n",
    "            anchor_groups[anchors[i].item()].append((negatives[i].item(), distances[i].item()))\n",
    "        \n",
    "        # For each anchor, select the hardest negatives\n",
    "        hard_a, hard_n = [], []\n",
    "        for anchor, neg_dists in anchor_groups.items():\n",
    "            # Sort negatives by distance (ascending for hardest cosine similarity)\n",
    "            neg_dists.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Select hardest fraction\n",
    "            num_to_select = max(1, int(len(neg_dists) * self.hardest_fraction))\n",
    "            selected_negs = neg_dists[:num_to_select]\n",
    "            \n",
    "            for neg, dist in selected_negs:\n",
    "                hard_a.append(anchor)\n",
    "                hard_n.append(neg)\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(hard_a, device=embeddings.device), \n",
    "            empty_tensor(0), \n",
    "            empty_tensor(0), \n",
    "            torch.tensor(hard_n, device=embeddings.device)\n",
    "        )\n",
    "        \n",
    "def empty_tensor(size):\n",
    "    return torch.tensor([], device=device, dtype=torch.long).view(size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training Pipeline\n",
    "\n",
    "Next, we'll implement the training pipeline for our metric learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, dataloaders, loss_type, optimizer, scheduler=None, num_epochs=25, embedding_size=128):\n",
    "    \"\"\"\n",
    "    Train the metric learning model\n",
    "    \"\"\"\n",
    "    # Get the number of training classes (excluding holdout classes)\n",
    "    num_training_classes = len(datasets_dict['class_mapping']['training_class_indices'])\n",
    "    \n",
    "    # Create loss function and miner\n",
    "    loss_func, mining_func = create_loss_and_miner(\n",
    "        loss_type=loss_type, \n",
    "        embedding_size=embedding_size, \n",
    "        num_classes=num_training_classes\n",
    "    )\n",
    "    \n",
    "    # If using ArcFace, we need to create a class map for the training dataset\n",
    "    if loss_type == 'arcface':\n",
    "        # Map original class indices to consecutive integers for ArcFace\n",
    "        class_map = {original: i for i, original in enumerate(datasets_dict['class_mapping']['training_class_indices'])}\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels in tqdm(dataloaders[phase], desc=phase):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Map labels for ArcFace if needed\n",
    "                if loss_type == 'arcface':\n",
    "                    # Filter out samples from holdout classes\n",
    "                    valid_idx = torch.tensor([i for i, l in enumerate(labels) if l.item() in class_map], device=device)\n",
    "                    if len(valid_idx) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    inputs = inputs[valid_idx]\n",
    "                    arcface_labels = torch.tensor([class_map[l.item()] for l in labels[valid_idx]], device=device)\n",
    "                    labels = arcface_labels\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    embeddings = model(inputs)\n",
    "                    \n",
    "                    # Get indices for mining if using a mining function\n",
    "                    if mining_func is not None:\n",
    "                        hard_pairs = mining_func(embeddings, labels)\n",
    "                        loss = loss_func(embeddings, labels, hard_pairs)\n",
    "                    else:\n",
    "                        loss = loss_func(embeddings, labels)\n",
    "                    \n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "                \n",
    "                # Save best model\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_loss\n",
    "                    torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Embedding Extraction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_embeddings(model, dataloader):\n",
    "    \"\"\"\n",
    "    Extract embeddings for a dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, batch_labels in tqdm(dataloader, desc=\"Extracting embeddings\"):\n",
    "            inputs = inputs.to(device)\n",
    "            batch_embeddings = model(inputs)\n",
    "            embeddings.append(batch_embeddings.cpu())\n",
    "            labels.append(batch_labels)\n",
    "    \n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Evaluation Functions\n",
    "\n",
    "### 1. Verification Task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_verification_pairs(embeddings, labels, num_pos_pairs=1000, num_neg_pairs=1000):\n",
    "    \"\"\"\n",
    "    Create positive and negative pairs for verification task\n",
    "    \"\"\"\n",
    "    unique_labels = torch.unique(labels)\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "    \n",
    "    # Generate positive pairs (same class)\n",
    "    pos_pair_count = 0\n",
    "    for label in unique_labels:\n",
    "        indices = torch.where(labels == label)[0]\n",
    "        if len(indices) >= 2:\n",
    "            for i in range(min(num_pos_pairs // len(unique_labels) + 1, len(indices) // 2)):\n",
    "                idx1, idx2 = np.random.choice(indices, 2, replace=False)\n",
    "                pairs.append((idx1.item(), idx2.item()))\n",
    "                pair_labels.append(1)  # 1 for same class\n",
    "                pos_pair_count += 1\n",
    "                if pos_pair_count >= num_pos_pairs:\n",
    "                    break\n",
    "        if pos_pair_count >= num_pos_pairs:\n",
    "            break\n",
    "    \n",
    "    # Generate negative pairs (different classes)\n",
    "    neg_pair_count = 0\n",
    "    while neg_pair_count < num_neg_pairs:\n",
    "        label1, label2 = np.random.choice(unique_labels, 2, replace=False)\n",
    "        indices1 = torch.where(labels == label1)[0]\n",
    "        indices2 = torch.where(labels == label2)[0]\n",
    "        \n",
    "        if len(indices1) > 0 and len(indices2) > 0:\n",
    "            idx1 = np.random.choice(indices1)\n",
    "            idx2 = np.random.choice(indices2)\n",
    "            pairs.append((idx1.item(), idx2.item()))\n",
    "            pair_labels.append(0)  # 0 for different class\n",
    "            neg_pair_count += 1\n",
    "    \n",
    "    return np.array(pairs), np.array(pair_labels)\n",
    "\n",
    "def evaluate_verification(embeddings, labels):\n",
    "    \"\"\"\n",
    "    Evaluate the model on verification task (same/different class)\n",
    "    \"\"\"\n",
    "    pairs, pair_labels = create_verification_pairs(embeddings, labels)\n",
    "    \n",
    "    # Compute distances between pairs\n",
    "    distances = []\n",
    "    for idx1, idx2 in pairs:\n",
    "        # Using cosine similarity (-1 to 1) where higher value means more similar\n",
    "        distance = F.cosine_similarity(\n",
    "            embeddings[idx1].unsqueeze(0), \n",
    "            embeddings[idx2].unsqueeze(0)\n",
    "        ).item()\n",
    "        distances.append(distance)\n",
    "    \n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    # Compute ROC curve and AUC\n",
    "    # Note: For cosine similarity, higher means more similar, so we need to negate it for ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(pair_labels, distances)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Compute Equal Error Rate (EER)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('verification_roc_curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'eer': eer,\n",
    "        'eer_threshold': eer_threshold,\n",
    "        'pairs': pairs,\n",
    "        'pair_labels': pair_labels,\n",
    "        'distances': distances\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Retrieval Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_retrieval(query_embeddings, query_labels, gallery_embeddings, gallery_labels, k_values=[1, 5, 10]):\n",
    "    \"\"\"\n",
    "    Evaluate the model on retrieval task\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = torch.matmul(query_embeddings, gallery_embeddings.T)\n",
    "        \n",
    "        # Get top-k indices for each query\n",
    "        _, indices = torch.topk(similarity_matrix, k=k, dim=1)\n",
    "        \n",
    "        # Compute Recall@K and Precision@K\n",
    "        recall_k = 0\n",
    "        precision_k = 0\n",
    "        \n",
    "        for i, query_label in enumerate(query_labels):\n",
    "            retrieved_labels = gallery_labels[indices[i]]\n",
    "            relevant = (retrieved_labels == query_label).float()\n",
    "            \n",
    "            # Recall@K: How many of the relevant items are retrieved\n",
    "            recall_k += (relevant.sum() > 0).float().item()\n",
    "            \n",
    "            # Precision@K: How many of the retrieved items are relevant\n",
    "            precision_k += (relevant.sum() / k).item()\n",
    "        \n",
    "        recall_k /= len(query_labels)\n",
    "        precision_k /= len(query_labels)\n",
    "        \n",
    "        results[f'recall@{k}'] = recall_k\n",
    "        results[f'precision@{k}'] = precision_k\n",
    "        \n",
    "        print(f\"Recall@{k}: {recall_k:.4f}\")\n",
    "        print(f\"Precision@{k}: {precision_k:.4f}\")\n",
    "    \n",
    "    return results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Few-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_few_shot(support_embeddings, support_labels, query_embeddings, query_labels, n_way=5, k_shot=5):\n",
    "    \"\"\"\n",
    "    Evaluate the model on n-way k-shot classification\n",
    "    \"\"\"\n",
    "    unique_labels = torch.unique(support_labels)\n",
    "    if len(unique_labels) < n_way:\n",
    "        print(f\"Warning: Only {len(unique_labels)} classes available, but n_way={n_way}\")\n",
    "        n_way = len(unique_labels)\n",
    "    \n",
    "    # Randomly select n classes\n",
    "    selected_classes = np.random.choice(unique_labels.numpy(), n_way, replace=False)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    # Run multiple episodes for stable results\n",
    "    num_episodes = 50\n",
    "    for episode in range(num_episodes):\n",
    "        # Create support set (k examples per class)\n",
    "        support_set_embeddings = []\n",
    "        support_set_labels = []\n",
    "        \n",
    "        for class_idx, c in enumerate(selected_classes):\n",
    "            # Get indices of examples of class c\n",
    "            class_indices = torch.where(support_labels == c)[0]\n",
    "            \n",
    "            # Randomly select k examples\n",
    "            if len(class_indices) >= k_shot:\n",
    "                selected_indices = np.random.choice(class_indices.numpy(), k_shot, replace=False)\n",
    "            else:\n",
    "                # If not enough examples, use all and repeat some\n",
    "                selected_indices = np.random.choice(class_indices.numpy(), k_shot, replace=True)\n",
    "            \n",
    "            for idx in selected_indices:\n",
    "                support_set_embeddings.append(support_embeddings[idx])\n",
    "                support_set_labels.append(class_idx)  # Use class index as the new label\n",
    "        \n",
    "        support_set_embeddings = torch.stack(support_set_embeddings)\n",
    "        support_set_labels = torch.tensor(support_set_labels)\n",
    "        \n",
    "        # Create query set (all examples of the selected classes from the query set)\n",
    "        query_set_indices = torch.tensor([i for i, label in enumerate(query_labels) if label in selected_classes])\n",
    "        \n",
    "        if len(query_set_indices) == 0:\n",
    "            print(\"Warning: No query examples for selected classes\")\n",
    "            continue\n",
    "            \n",
    "        query_set_embeddings = query_embeddings[query_set_indices]\n",
    "        query_set_labels = query_labels[query_set_indices]\n",
    "        \n",
    "        # Map original labels to new indices (0 to n_way-1)\n",
    "        label_mapping = {selected_classes[i]: i for i in range(n_way)}\n",
    "        query_set_labels = torch.tensor([label_mapping[label.item()] for label in query_set_labels])\n",
    "        \n",
    "        # Compute prototypes (mean embedding for each class)\n",
    "        prototypes = torch.zeros(n_way, support_embeddings.size(1), device=support_embeddings.device)\n",
    "        for c in range(n_way):\n",
    "            prototypes[c] = support_set_embeddings[support_set_labels == c].mean(0)\n",
    "        \n",
    "        # Compute distances between query examples and prototypes\n",
    "        # Using cosine similarity (higher means more similar)\n",
    "        logits = torch.matmul(query_set_embeddings, prototypes.T)\n",
    "        \n",
    "        # Make predictions\n",
    "        _, predictions = torch.max(logits, dim=1)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        accuracy = (predictions == query_set_labels).float().mean().item()\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    \n",
    "    print(f\"{n_way}-way {k_shot}-shot classification accuracy: {mean_accuracy:.4f} Â± {std_accuracy:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'mean_accuracy': mean_accuracy,\n",
    "        'std_accuracy': std_accuracy,\n",
    "        'accuracies': accuracies\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Embedding Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_embeddings(embeddings, labels, class_mapping, method='tsne', title='Embedding Visualization'):\n",
    "    \"\"\"\n",
    "    Visualize embeddings using t-SNE or UMAP\n",
    "    \"\"\"\n",
    "    idx_to_class = class_mapping['idx_to_class']\n",
    "    \n",
    "    # Reduce dimensionality\n",
    "    if method == 'tsne':\n",
    "        print(\"Computing t-SNE projection...\")\n",
    "        projection = TSNE(n_components=2, random_state=42).fit_transform(embeddings.numpy())\n",
    "    elif method == 'umap':\n",
    "        print(\"Computing UMAP projection...\")\n",
    "        projection = umap.UMAP(n_components=2, random_state=42).fit_transform(embeddings.numpy())\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported visualization method: {method}\")\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Get unique labels\n",
    "    unique_labels = torch.unique(labels).numpy()\n",
    "    \n",
    "    # Create colormap\n",
    "    cmap = plt.cm.get_cmap('tab20', len(unique_labels))\n",
    "    \n",
    "    # Plot each class\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        mask = labels.numpy() == label\n",
    "        plt.scatter(\n",
    "            projection[mask, 0],\n",
    "            projection[mask, 1],\n",
    "            c=[cmap(i)],\n",
    "            label=idx_to_class[label],\n",
    "            alpha=0.7,\n",
    "            s=50\n",
    "        )\n",
    "    \n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{method}_visualization.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return projection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Grad-CAM Visualization (Bonus Implementation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_grad_cam(model, dataloader, class_mapping, num_images=5):\n",
    "    \"\"\"\n",
    "    Visualize Grad-CAM attention maps\n",
    "    \"\"\"\n",
    "    # Import GradCAM implementation\n",
    "    try:\n",
    "        from pytorch_grad_cam import GradCAM\n",
    "        from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    except ImportError:\n",
    "        print(\"Please install pytorch-grad-cam to use this function:\")\n",
    "        print(\"!pip install grad-cam\")\n",
    "        return\n",
    "    \n",
    "    # Set up GradCAM\n",
    "    # We need to adjust this depending on the backbone architecture\n",
    "    target_layers = [model.backbone[-2][-1].conv2]  # Last conv layer for ResNet\n",
    "    \n",
    "    grad_cam = GradCAM(model=model, target_layers=target_layers, use_cuda=torch.cuda.is_available())\n",
    "    \n",
    "    # Get a batch of images\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images[:num_images]\n",
    "    labels = labels[:num_images]\n",
    "    \n",
    "    # Convert images for visualization\n",
    "    orig_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        img = (img * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        orig_images.append(img)\n",
    "    \n",
    "    # Generate class activation maps\n",
    "    cam_images = []\n",
    "    for i in range(len(images)):\n",
    "        input_tensor = images[i].unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get embeddings for target image\n",
    "        embedding = model(input_tensor)\n",
    "        \n",
    "        # Generate GradCAM\n",
    "        grayscale_cam = grad_cam(input_tensor)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        \n",
    "        # Overlay on original image\n",
    "        cam_image = show_cam_on_image(orig_images[i], grayscale_cam, use_rgb=True)\n",
    "        cam_images.append(cam_image)\n",
    "    \n",
    "    # Plot original images and their activation maps\n",
    "    plt.figure(figsize=(15, 4 * num_images))\n",
    "    for i in range(num_images):\n",
    "        # Original image\n",
    "        plt.subplot(num_images, 2, 2*i+1)\n",
    "        plt.imshow(orig_images[i])\n",
    "        plt.title(f\"Original: {class_mapping['idx_to_class'][labels[i].item()]}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # GradCAM\n",
    "        plt.subplot(num_images, 2, 2*i+2)\n",
    "        plt.imshow(cam_images[i])\n",
    "        plt.title(\"GradCAM\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('grad_cam_visualization.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Main Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # Model parameters\n",
    "    backbone_name = 'resnet18'  # Options: 'resnet18', 'resnet50'\n",
    "    embedding_size = 128\n",
    "    batch_size = 32  # Adjust based on your GPU\n",
    "    \n",
    "    # Training parameters\n",
    "    loss_type = 'triplet'  # Options: 'triplet', 'contrastive', 'arcface'\n",
    "    num_epochs = 20\n",
    "    lr = 1e-4\n",
    "    \n",
    "    # Load data\n",
    "    train_val_dataset, test_dataset, eval_train_dataset = load_oxford_pets_dataset()\n",
    "    datasets_dict = prepare_datasets(train_val_dataset, test_dataset, eval_train_dataset)\n",
    "    dataloaders = create_dataloaders(datasets_dict, batch_size=batch_size)\n",
    "    \n",
    "    # Create model\n",
    "    model = EmbeddingNet(backbone_name=backbone_name, embedding_size=embedding_size)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create optimizer and scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    # Train model\n",
    "    model, history = train_model(\n",
    "        model=model,\n",
    "        dataloaders=dataloaders,\n",
    "        loss_type=loss_type,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=num_epochs,\n",
    "        embedding_size=embedding_size\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs+1), history['train_loss'], 'b-', label='Training Loss')\n",
    "    plt.plot(range(1, num_epochs+1), history['val_loss'], 'r-', label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Loss ({loss_type} loss)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Extract embeddings for evaluation\n",
    "    print(\"\\nExtracting embeddings for evaluation...\")\n",
    "    train_embeddings, train_labels = extract_embeddings(model, dataloaders['eval_train'])\n",
    "    test_embeddings, test_labels = extract_embeddings(model, dataloaders['test'])\n",
    "    few_shot_train_embeddings, few_shot_train_labels = extract_embeddings(model, dataloaders['few_shot_train'])\n",
    "    few_shot_test_embeddings, few_shot_test_labels = extract_embeddings(model, dataloaders['few_shot_test'])\n",
    "    \n",
    "    # Evaluation tasks\n",
    "    print(\"\\n1. Verification Task:\")\n",
    "    verification_results = evaluate_verification(test_embeddings, test_labels)\n",
    "    \n",
    "    print(f\"\\nVerification Results:\")\n",
    "    print(f\"ROC AUC: {verification_results['roc_auc']:.4f}\")\n",
    "    print(f\"Equal Error Rate (EER): {verification_results['eer']:.4f}\")\n",
    "    \n",
    "    print(\"\\n2. Retrieval Task:\")\n",
    "    retrieval_results = evaluate_retrieval(\n",
    "        query_embeddings=test_embeddings,\n",
    "        query_labels=test_labels,\n",
    "        gallery_embeddings=train_embeddings,\n",
    "        gallery_labels=train_labels,\n",
    "        k_values=[1, 5, 10]\n",
    "    )\n",
    "    \n",
    "    print(\"\\n3. Few-shot Classification:\")\n",
    "    few_shot_results = evaluate_few_shot(\n",
    "        support_embeddings=few_shot_train_embeddings,\n",
    "        support_labels=few_shot_train_labels,\n",
    "        query_embeddings=few_shot_test_embeddings,\n",
    "        query_labels=few_shot_test_labels,\n",
    "        n_way=5,\n",
    "        k_shot=5\n",
    "    )\n",
    "    \n",
    "    # Embedding visualization\n",
    "    print(\"\\n4. Embedding Visualization:\")\n",
    "    test_projection = visualize_embeddings(\n",
    "        embeddings=test_embeddings,\n",
    "        labels=test_labels,\n",
    "        class_mapping=datasets_dict['class_mapping'],\n",
    "        method='tsne',\n",
    "        title='t-SNE Visualization of Test Embeddings'\n",
    "    )\n",
    "    \n",
    "    # Visualize few-shot embeddings\n",
    "    print(\"\\nVisualizing few-shot embeddings:\")\n",
    "    # Combine few-shot train and test embeddings for visualization\n",
    "    all_few_shot_embeddings = torch.cat([few_shot_train_embeddings, few_shot_test_embeddings], dim=0)\n",
    "    all_few_shot_labels = torch.cat([few_shot_train_labels, few_shot_test_labels], dim=0)\n",
    "    \n",
    "    few_shot_projection = visualize_embeddings(\n",
    "        embeddings=all_few_shot_embeddings,\n",
    "        labels=all_few_shot_labels,\n",
    "        class_mapping=datasets_dict['class_mapping'],\n",
    "        method='tsne',\n",
    "        title='t-SNE Visualization of Few-Shot Embeddings'\n",
    "    )\n",
    "    \n",
    "    # Bonus: Grad-CAM Visualization\n",
    "    print(\"\\n5. Grad-CAM Visualization:\")\n",
    "    visualize_grad_cam(model, dataloaders['test'], datasets_dict['class_mapping'], num_images=3)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'embedding_size': embedding_size,\n",
    "        'backbone_name': backbone_name,\n",
    "        'class_mapping': datasets_dict['class_mapping']\n",
    "    }, f'pet_metric_learning_{backbone_name}_{loss_type}.pth')\n",
    "    \n",
    "    print(\"\\nEvaluation completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Bonus: Multiple Loss Function Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_loss_functions():\n",
    "    \"\"\"\n",
    "    Compare different loss functions for metric learning\n",
    "    \"\"\"\n",
    "    # Model parameters\n",
    "    backbone_name = 'resnet18'\n",
    "    embedding_size = 128\n",
    "    batch_size = 32\n",
    "    num_epochs = 15\n",
    "    \n",
    "    # Loss functions to compare\n",
    "    loss_types = ['triplet', 'contrastive', 'arcface']\n",
    "    \n",
    "    # Load data (only once)\n",
    "    train_val_dataset, test_dataset, eval_train_dataset = load_oxford_pets_dataset()\n",
    "    datasets_dict = prepare_datasets(train_val_dataset, test_dataset, eval_train_dataset)\n",
    "    dataloaders = create_dataloaders(datasets_dict, batch_size=batch_size)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for loss_type in loss_types:\n",
    "        print(f\"\\n{'=' * 40}\")\n",
    "        print(f\"Training with {loss_type} loss\")\n",
    "        print(f\"{'=' * 40}\")\n",
    "        \n",
    "        # Create model\n",
    "        model = EmbeddingNet(backbone_name=backbone_name, embedding_size=embedding_size)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Create optimizer and scheduler\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "        \n",
    "        # Train model\n",
    "        model, history = train_model(\n",
    "            model=model,\n",
    "            dataloaders=dataloaders,\n",
    "            loss_type=loss_type,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            num_epochs=num_epochs,\n",
    "            embedding_size=embedding_size\n",
    "        )\n",
    "        \n",
    "        # Extract embeddings for evaluation\n",
    "        print(\"\\nExtracting embeddings for evaluation...\")\n",
    "        train_embeddings, train_labels = extract_embeddings(model, dataloaders['eval_train'])\n",
    "        test_embeddings, test_labels = extract_embeddings(model, dataloaders['test'])\n",
    "        \n",
    "        # Evaluation\n",
    "        verification_results = evaluate_verification(test_embeddings, test_labels)\n",
    "        \n",
    "        retrieval_results = evaluate_retrieval(\n",
    "            query_embeddings=test_embeddings,\n",
    "            query_labels=test_labels,\n",
    "            gallery_embeddings=train_embeddings,\n",
    "            gallery_labels=train_labels,\n",
    "            k_values=[1, 5]\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[loss_type] = {\n",
    "            'verification': {\n",
    "                'roc_auc': verification_results['roc_auc'],\n",
    "                'eer': verification_results['eer']\n",
    "            },\n",
    "            'retrieval': {\n",
    "                'recall@1': retrieval_results['recall@1'],\n",
    "                'recall@5': retrieval_results['recall@5'],\n",
    "                'precision@1': retrieval_results['precision@1'],\n",
    "                'precision@5': retrieval_results['precision@5']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save model\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'embedding_size': embedding_size,\n",
    "            'backbone_name': backbone_name,\n",
    "            'class_mapping': datasets_dict['class_mapping']\n",
    "        }, f'pet_metric_learning_{backbone_name}_{loss_type}_comparison.pth')\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\n{'='*50}\")\n",
    "    print(\"Comparison of Loss Functions\")\n",
    "    print({'='*50})\n",
    "    \n",
    "    # Create a comparison table\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Loss Function': [],\n",
    "        'ROC AUC': [],\n",
    "        'EER': [],\n",
    "        'Recall@1': [],\n",
    "        'Recall@5': [],\n",
    "        'Precision@1': [],\n",
    "        'Precision@5': []\n",
    "    })\n",
    "    \n",
    "    for loss_type, metrics in results.items():\n",
    "        comparison_df = comparison_df.append({\n",
    "            'Loss Function': loss_type,\n",
    "            'ROC AUC': metrics['verification']['roc_auc'],\n",
    "            'EER': metrics['verification']['eer'],\n",
    "            'Recall@1': metrics['retrieval']['recall@1'],\n",
    "            'Recall@5': metrics['retrieval']['recall@5'],\n",
    "            'Precision@1': metrics['retrieval']['precision@1'],\n",
    "            'Precision@5': metrics['retrieval']['precision@5']\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    metrics = ['ROC AUC', 'Recall@1', 'Recall@5', 'Precision@1', 'Precision@5']\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, loss_type in enumerate(loss_types):\n",
    "        values = [\n",
    "            results[loss_type]['verification']['roc_auc'],\n",
    "            results[loss_type]['retrieval']['recall@1'],\n",
    "            results[loss_type]['retrieval']['recall@5'],\n",
    "            results[loss_type]['retrieval']['precision@1'],\n",
    "            results[loss_type]['retrieval']['precision@5']\n",
    "        ]\n",
    "        plt.bar(x + i*width, values, width, label=loss_type)\n",
    "    \n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Comparison of Loss Functions')\n",
    "    plt.xticks(x + width, metrics)\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.savefig('loss_function_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return results, comparison_df\n",
    "\n",
    "# Uncomment to run the comparison\n",
    "# loss_comparison_results, loss_comparison_df = compare_loss_functions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Bonus: Streamlit Demo\n",
    "\n",
    "The Streamlit demo code has been moved to a separate file: `pet_similarity_app.py`.\n",
    "\n",
    "To run the demo:\n",
    "1. Ensure you have Streamlit installed (`pip install streamlit`).\n",
    "2. Make sure a trained model file (e.g., `pet_metric_learning_resnet18_triplet.pth`) exists in the same directory.\n",
    "3. Run the command: `streamlit run pet_similarity_app.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we have implemented a comprehensive metric learning pipeline for pet breed classification using the Oxford-IIIT Pet Dataset. We have:\n",
    "\n",
    "1. Built a custom embedding model with a CNN backbone and projection head\n",
    "2. Implemented various loss functions for metric learning (Triplet, Contrastive, ArcFace)\n",
    "3. Developed evaluation methods for verification, retrieval, and few-shot classification\n",
    "4. Created visualization tools for embedding spaces and feature importance (Grad-CAM)\n",
    "5. Included bonus implementations for hard negative mining and loss function comparison\n",
    "6. Moved the Streamlit demo to a separate `pet_similarity_app.py` file.\n",
    "\n",
    "The code is modular and can be easily adapted for different settings and experimentation. To run the complete training and evaluation pipeline, simply execute the `main()` function."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
